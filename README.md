# 环境相关
```bash
# 导出依赖包
conda env export >  model-doctor-conf.yml

# 从依赖文件重建环境
conda env create -f model-doctor-conf.yml
```

# 记得每次训练修改保存结果目录

# 使用模型医生微调FC层步骤
 1. 修改 `models` 文件夹下 `__init__.py` 文件 `load_modules` 函数
    - `module_modules` 字典，`-1`这个 key 对应层数修改成倒数第二层 FC 层
 2. 使用 `core` 文件夹下 `grad_sift_fc.py` 文件生成对应的 `channel mask`
 3. 修改 `core` 文件夹下 `grad_constraint.py` 文件
    - 注释第 39 行
    - 取消第 40 行的注释
4. 使用以前的逻辑微调模型

# 添加数据集步骤
1. 准备数据集
2. 参考 `loaders` 文件夹的数据加载器，自己写一个数据加载器
3. 在 `loaders` 文件夹的 `__init__.py` 文件注册自己的数据加载器，需要改两个地方
    - `load_data` 函数里面 `if` 判断两种情况都要加上


# 常规数据集训练
## resnet50+cifar10
1. 从头训练一个模型: 0.9489
2. 原有的模型医生调整: 0.9548, + 0.5900%
3. 只使用正梯度(grad_sift文件用的正梯度，grad_constraint用的绝对值): 0.9562, + 0.7300%
4. 只使用正梯度(grad_sift文件用的正梯度，grad_constraint用的正梯度): 0.9552, + 0.6300%
5. 只使用正激活部分对应的梯度(生成 mask 和训练都这样做): 0.9600, + 1.1100%（batch=16)，0.9542, + 0.5300%(batch=128)
6. 用正激活代替梯度筛选mask，但是训练的时候，使用原有的梯度，正梯度正常约束，负梯度全部约束: 0.9536, + 0.4700%
7. 正激活和正梯度生成的mask取交集，训练同6: 0.9548, + 0.5900%
8. 正激活和正梯度生成的mask取并集，训练同6: 0.9533, + 0.4400%
9. 用正激活部分对应的梯度筛选mask，训练的时候采用原有md方法: 0.9550, + 0.6100%，
    - 0.9575, + 0.8600%（batchsize=64)
    - 0.9600, + 1.1100%（batchsize=32）
10. 用正激活部分对应的梯度筛选mask，训练同6: 0.9545, + 0.5600%
11. 使用正梯度生成mask channel,训练同6：0.9540, + 0.5100%
12. 用正激活代替梯度筛选mask，训练的时候采用原有md方法: 0.9557, + 0.6800%
13. 同上，lr=0.005: 0.9526, + 0.3700%
14. 同上，lr=1e-4: 0.9482, + -0.0700%
15. 原始md，lr=1e-4: 0.9484, + -0.0500%

16. 2021年12月26日
    - 从头训练: acc is 0.9484(最优的val acc)
    - md: 0.9550

# 验证模型医生应用到FC层是否有效

如果使用模型医生, vgg16 的 loss_channel 的放缩比应该是1，res50应该是10
alexnet 只有5层卷积
验证模型医生对卷积层有效，可用的模型：alexnet，vgg16，senet34

## vgg16+stl10
- 从头训练: 0.7094
- 使用模型医生调整倒数第二层 FC: 0.7374
- 倒数第一层卷积层: 0.7375


## vgg16+mini-imagenet
- 从头训练：0.7703


## senet34+stl10
- 预训练模型：0.8200


## alexnet+stl10
- 师兄用的正数第二层卷积，我这里用的倒数第一层卷积
- 从头训练：0.6584
- 1倍channel loss：78轮loss开始变成nan
- 0.1倍loss：116轮开始分类的loss开始变成恒定2左右


## alexnetv2+stl10
- 使用pytorch官方给的模型结构从头训练：0.6985
- 1倍channel loss, 原始的模型医生：0.7258
- 1倍channel loss, 倒数第二层 FC 层：0.7061


## alexnetv2+cifar10(图片resize成224x224)
- 模型结果从pytorch官方直接拷贝得到的
- 预训练模型：0.9036
- 10倍channel loss，模型医生：0.9052
- 10倍channel loss，FC+模型医生：0.9014


## alexnetv3+cifar10（图片大小32x32）
- 这个模型改了alexnetv2第一层卷积层的参数，最后一层池化使用自适应池化代替
- 预训练模型：0.8513
- 10倍channel loss，准确率在 10%，一直上不去，原始分类的loss在 2 左右不变，如果去除添加的噪声，分类的loss变成0.25左右
猜想师兄用的 torch.randn 对特征图改变较大（猜想正确，去除噪声能正常训练起来了），但是我没跑最终的实验
- 1倍channel loss: 0.8555


## alexnetv2+cifar10(图片resize成64x64)
- 预训练模型：0.8389

- 10倍channel loss, 倒数第二层 FC 层：0.8408
- 1倍channel loss, 倒数第二层 FC 层：0.8326

- 1倍channel loss, 倒数第一层卷积, 原始模型医生: 训练不起来
- 1倍channel loss, 倒数第一层卷积, 模型医生不加噪音，可以训练起来：0.8347

- 10倍channel loss, 倒数第一层卷积, 原始模型医生：0.8111(训练了400轮，train还没到100%)
    - 有时候一开始训练loss就nan了，可以kill掉重新开始
- 10倍channel loss, 倒数第一层卷积, 模型医生不加噪音：

# 长尾数据集+模型医生
## cifar-10(ρ=100)类别分布
| 类别 | 数量 |
| ---  | --- |
| 0 | 5000 |
| 1 | 2997 |
| 2 | 1796 |
| 3 | 1077 |
| 4 | 645 |
| 5 | 387 |
| 6 | 232 |
| 7 | 139 |
| 8 | 83 |
| 9 | 50 |


# ResNext50+ImageNet-lt
- 预训练：acc1 is 40.45%, acc5 is 65.85%

# ResNet32+Cifar-100-lt-ir100（直接训练）
- CE loss: acc1 is 40.58%, acc5 is 69.95%, err1 is **59.42%**, err5 is 30.05%
- FL: acc1 is 39.11%, acc5 is 69.10%, err1 is **60.89%**, err5 is 30.90%
- REFL
    - th=0.5: acc1 is 41.77%, acc5 is 71.12%, err1 is **58.23%**,
    - th=0.4: acc1 is 36.97%, acc5 is 67.70%;（自定义学习率）: acc1 is 39.73%, acc5 is 68.50%, err1 is **60.27%**, err5 is 31.50%
    - th=0.3: acc1 is 36.65%, acc5 is 61.91%
- EFL: acc1 is 38.94%, acc5 is 68.23%, err1 is 61.06%, err5 is 31.77%
- REFL+MD:
    - th=0.2, 初始学习率0.01: acc1 is 41.60%
    - th=0.2, 初始学习率0.001: acc1 is 42.48%
    - th=0.1, 初始学习率0.001: acc1 is 41.64%, acc5 is 71.24%

# 2022年3月3日

目前实验的实验步骤:
1. 使用普通的数据加载器和模型训练，loss函数使用REFL，使用自定义的学习率调度器
2. 使用步骤1训练好的模型再次在**训练集**上面跑一遍（普通的数据加载器），挑选高置信的图片
    - 使用 `image_sift.py` 筛选图片
3. 拿着步骤2得到的图片，使用 `pattern_sift.py` 算每个类别的高于平均梯度的卷积核
4. 使用 `读取npy.py` 合并每个类别有关的卷积核
5. 使用 kernel_dict 文件夹下面的脚本训练模型

# ResNet32+Cifar-10-lt-ir100（直接训练）
- CE loss，**baseline**: acc1 is `69.34%`, err rate is `30.66%`, CB论文可以做到 err `29.64%`
- REFL
    - th=0.5: acc1 is 68.69%
    - th=0.4: acc1 is 70.72%, err rate is 29.28%; acc1 is **71.82%**, err1 is **28.18%**（自定义学习率）, 后续的SOTA模型
    - th=0.3: acc1 is 70.25%
    - th=0.25: acc1 is 66.55%
- REFL+CBS
    - th=0.5
        - lr=1e-2: 70.99%
        - lr=1e-3: 59.61%
- REFL V2
    - th=0.5: acc1 is 65.66%
    - th=0.4: acc1 is 67.53%
- REFL V3
    - th=0.4: acc1 is 69.61%
- REFL V4:
    - th=0.4: acc1 is 68.55%
- FL: acc1 is 69.20%
- EFL: acc1 is 67.79%
- DFL: acc1 is 70.71%
- RFL: acc1 is 68.66%
- REFL+MD（初始学习率0.01）
    - th=0.5: acc1 is 73.21%
    - th=0.4: acc1 is 74.14%, (余弦, init_lr=0.01): acc1 is 72.97%
    - th=0.3: acc1 is 74.76%
    - th=0.25: acc1 is **74.92%**
    - th=0.2: acc1 is 73.09%


- 以下默认使用refl，挑选卷积核使用**测试集**高置信度图片，除非另加说明(数据泄露)
- baseline: 71.82%
- 挑选卷积核(最后一层卷积核)
    - 自定义学习率: 72.82%
    - 只选最后一个尾部类
        - 余弦退火, th=0.5:  **73.11%**
        - 余弦退火, th=0.4:  72.85%
        - 余弦退火, th=0.25: 72.98%
    - 选最后2个尾部类
        - 余弦退火, th=0.5:  72.53%
    - 选最后3个尾部类
        - 余弦退火, th=0.5:  72.67%
    - 选5、7、9类
        - 余弦退火, th=0.5:  72.48%
- 挑选卷积核（所有层）
    -  只选最后一个尾部类
        - 余弦退火, th=0.5:  72.98%
- 挑选卷积核（最后10层）
    - 只选最后一个尾部类
        - 余弦退火, th=0.5:   **73.10%**
        - 自定义学习率, th=0.5: 73.05%
    - 选最后两个类
        - 余弦退火, th=0.5:     72.66%
        - 自定义学习率, th=0.5:  72.62%
        - 余弦退火, th=0.5, fl: 72.97%
        - 自定义学习率, th=0.5, fl: **73.40%**

- 下面的使用**训练集**高置信度图片挑选卷积核, 默认使用refl
- baseline: 71.82%
- 挑选卷积核（最后10层）
    - 选最后两个类
        - 自定义学习率, th=0.5, fl: 72.93%
        - 自定义学习率, th=0.5: **73.94%**
    - 后3个类
        - 余弦退火,th=0.5: 72.43%
        - 自定义学习率, th=0.5: 72.55%
    - **选的尾部类太多会掉点**
- 上面的代码有误，导致前20层正常更新，后10层只更新了部分卷积核
- 挑选卷积核（所有层）
    - 选最后两个类
        - 自定义学习率, th=0.5: 72.65%
        - 余弦退火,th=0.5: 72.62%
- 挑选卷积核（最后10层，前面20层不进行梯度更新）
    - 后3个类
        - 自定义学习率, th=0.5: 72.36%
- 挑选卷积核（使用对应类别图片的loss更新对应的卷积核，未加说明th=0.5）
    - lr=0.01
        - 自定义学习率，所有类别，后10层: 65.49%
        - 自定义学习率，所有类别，所有层: 63.29%
        - 同上，但是反向调整卷积核: 66.06%
        - (消融实验)自定义学习率，类别平衡采样(CBS)，REFL，不更新卷积核: **77.20%**, Epoch 2
    - lr=1e-4
        - 自定义学习率，所有类别，所有层: 74.14%, Epoch 8
        - 同上，但是反向调整卷积核: 74.16%, Epoch 7
        - 余弦退火，其余同1: 74.81%, Epoch 2
    - lr=1e-5
        - 自定义学习率，所有类别，所有层: **75.77%**, Epoch 26
        - 余弦退火，其余同1: 75.33%, Epoch 26
        - 自定义学习率，所有类别，所有层，th=0.4: 74.11%, Epoch 14
        - 自定义学习率，所有类别，所有层，th=0.6: 75.05%, Epoch 38
        - 使用类别均衡采样策略，其余同1: 75.55%, Epoch 9(中途服务器挂了，只跑了165轮); 74.79%, Epoch 10
    - lr=1e-6
        - 自定义学习率，所有类别，所有层: **75.90%**, Epoch 179
        - 自定义学习率, 所有类别, 所有层, th=0.4: 75.57%, Epoch 145
        - 使用类别均衡采样策略，其余同1: 75.89%, Epoch 75
    


尝试了使用特定类别的图片
1. 更新对应的卷积核（没啥用）
2. 反向更新卷积核（没啥用）
3. 只手动更新后十层，其余层自行更新（没啥用）
4. 调整学习率为1e-4，有效果
5. 调整学习率为1e-5，效果提升显著，提升了 2 个点
6. 不调整卷积核，仅仅在预训练模型上面加了CBS和REFL，不调整卷积核，提升了 6 个点，结果比以前都要好（好过调整卷积核的实验）


训练集准确率低的原因：同一批数据，不同类别的图片进去的时候模型状态已经改变了

从loss曲线可以看出，lr=1e-6或者1e-5比较合适，然后进行微调较为合适，调整100轮应该就可以了

cifar 数据集大概调整 50 轮就可以了



应该对模块的输出求导，不应该对输入求导，需要修改很多部分：
pattern_sift， 求梯度，模型模块定义那边

```bash
git config --global user.name tcmyxc
git config --global user.email 1282494272@qq.com
```

```bash
$(date "+%Y%m%d-%H%M%S").log
```


# ResNet32+Cifar-10-lt-ir100
- 预训练：71.82%(refl), (ce:69.34%, fl:69.20%)
- 同一个类别，不相关卷积核的特征图向相关卷积核靠近(需要重做)
    - lr1e-3, refl, cosine: (153612)
    - lr1e-3, ce, cosine: 71.29%
    - lr1e-3, fl, cosine: 72.65% (验证集acc一直下降)
- 分类错误样本，不相关卷积核的特征图向聚类中心靠近(需要重做)
    - lr1e-3, refl, cosine: 71.85% (152141)
    - lr1e-3, ce, cosine: 71.51 (验证集acc呈下降趋势)
    - lr1e-3, fl, cosine: 72.43% (验证集acc一直下降)
- 分类错误样本的特征图向聚类中心靠近(需要重做)
    - lr1e-3, refl, cosine: 
    - lr1e-3, ce, cosine: 
    - lr1e-3, fl, cosine: 
- 分类错误样本，不相关卷积核的特征图向聚类中心靠近（训练的时候只使用特征图对应的loss，测试用ce_loss）
    - lr1e-3, cosine:
    - lr1e-3, custom:

# ResNet32+Cifar-100-lt-ir100
- 预训练：41.77%(REFL), (CE:40.58%, FL:39.11%)
- 同一个类别，不相关卷积核的特征图向相关卷积核靠近(最多挑选5张图片筛选卷积核)


timm 库 accuracy